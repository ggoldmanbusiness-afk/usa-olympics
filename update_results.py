#!/usr/bin/env python3
â€œâ€â€
Update Olympics results from Wikipedia (primary) with Claude API fallback.
Fetches medal table and marks completed events.
â€œâ€â€

import json
import re
import sys
import os
from datetime import datetime, timezone, timedelta
from urllib.request import urlopen, Request
from urllib.error import URLError
from html.parser import HTMLParser

DATA_FILE = os.path.join(os.path.dirname(**file**), â€œdata.jsonâ€)
WIKI_MEDAL_URL = â€œhttps://en.wikipedia.org/wiki/2026_Winter_Olympics_medal_tableâ€
WIKI_RESULTS_URL = â€œhttps://en.wikipedia.org/wiki/2026_Winter_Olympicsâ€

# Country code to flag emoji mapping

FLAG_MAP = {
â€œNORâ€: â€œğŸ‡³ğŸ‡´â€, â€œUSAâ€: â€œğŸ‡ºğŸ‡¸â€, â€œITAâ€: â€œğŸ‡®ğŸ‡¹â€, â€œJPNâ€: â€œğŸ‡¯ğŸ‡µâ€, â€œAUTâ€: â€œğŸ‡¦ğŸ‡¹â€,
â€œGERâ€: â€œğŸ‡©ğŸ‡ªâ€, â€œCZEâ€: â€œğŸ‡¨ğŸ‡¿â€, â€œFRAâ€: â€œğŸ‡«ğŸ‡·â€, â€œSWEâ€: â€œğŸ‡¸ğŸ‡ªâ€, â€œSUIâ€: â€œğŸ‡¨ğŸ‡­â€,
â€œCHEâ€: â€œğŸ‡¨ğŸ‡­â€, â€œKORâ€: â€œğŸ‡°ğŸ‡·â€, â€œSLOâ€: â€œğŸ‡¸ğŸ‡®â€, â€œBULâ€: â€œğŸ‡§ğŸ‡¬â€, â€œCANâ€: â€œğŸ‡¨ğŸ‡¦â€,
â€œCHNâ€: â€œğŸ‡¨ğŸ‡³â€, â€œNEDâ€: â€œğŸ‡³ğŸ‡±â€, â€œFINâ€: â€œğŸ‡«ğŸ‡®â€, â€œGBRâ€: â€œğŸ‡¬ğŸ‡§â€, â€œAUSâ€: â€œğŸ‡¦ğŸ‡ºâ€,
â€œNZLâ€: â€œğŸ‡³ğŸ‡¿â€, â€œESPâ€: â€œğŸ‡ªğŸ‡¸â€, â€œPOLâ€: â€œğŸ‡µğŸ‡±â€, â€œBELâ€: â€œğŸ‡§ğŸ‡ªâ€, â€œROUâ€: â€œğŸ‡·ğŸ‡´â€,
â€œHUNâ€: â€œğŸ‡­ğŸ‡ºâ€, â€œCROâ€: â€œğŸ‡­ğŸ‡·â€, â€œSVKâ€: â€œğŸ‡¸ğŸ‡°â€, â€œUKRâ€: â€œğŸ‡ºğŸ‡¦â€, â€œBLRâ€: â€œğŸ‡§ğŸ‡¾â€,
â€œKAZâ€: â€œğŸ‡°ğŸ‡¿â€, â€œLATâ€: â€œğŸ‡±ğŸ‡»â€, â€œESTâ€: â€œğŸ‡ªğŸ‡ªâ€, â€œLTUâ€: â€œğŸ‡±ğŸ‡¹â€, â€œDENâ€: â€œğŸ‡©ğŸ‡°â€,
}

# Full country names for codes

COUNTRY_NAMES = {
â€œNORâ€: â€œNorwayâ€, â€œUSAâ€: â€œUnited Statesâ€, â€œITAâ€: â€œItalyâ€, â€œJPNâ€: â€œJapanâ€,
â€œAUTâ€: â€œAustriaâ€, â€œGERâ€: â€œGermanyâ€, â€œCZEâ€: â€œCzechiaâ€, â€œFRAâ€: â€œFranceâ€,
â€œSWEâ€: â€œSwedenâ€, â€œSUIâ€: â€œSwitzerlandâ€, â€œCHEâ€: â€œSwitzerlandâ€, â€œKORâ€: â€œSouth Koreaâ€,
â€œSLOâ€: â€œSloveniaâ€, â€œBULâ€: â€œBulgariaâ€, â€œCANâ€: â€œCanadaâ€, â€œCHNâ€: â€œChinaâ€,
â€œNEDâ€: â€œNetherlandsâ€, â€œFINâ€: â€œFinlandâ€, â€œGBRâ€: â€œGreat Britainâ€, â€œAUSâ€: â€œAustraliaâ€,
â€œNZLâ€: â€œNew Zealandâ€, â€œESPâ€: â€œSpainâ€, â€œPOLâ€: â€œPolandâ€, â€œBELâ€: â€œBelgiumâ€,
â€œROUâ€: â€œRomaniaâ€, â€œHUNâ€: â€œHungaryâ€, â€œCROâ€: â€œCroatiaâ€, â€œSVKâ€: â€œSlovakiaâ€,
â€œUKRâ€: â€œUkraineâ€, â€œKAZâ€: â€œKazakhstanâ€, â€œLATâ€: â€œLatviaâ€, â€œESTâ€: â€œEstoniaâ€,
â€œLTUâ€: â€œLithuaniaâ€, â€œDENâ€: â€œDenmarkâ€,
}

def fetch_url(url):
â€œâ€â€œFetch URL content with a browser-like user agent.â€â€â€
req = Request(url, headers={
â€œUser-Agentâ€: â€œMozilla/5.0 (compatible; OlympicsTracker/1.0)â€
})
try:
with urlopen(req, timeout=15) as resp:
return resp.read().decode(â€œutf-8â€, errors=â€œreplaceâ€)
except URLError as e:
print(fâ€  âš ï¸  Failed to fetch {url}: {e}â€)
return None

def parse_wiki_medal_table(html):
â€œâ€â€
Parse the Wikipedia medal table page.
Returns list of dicts with country medal counts.
â€œâ€â€
if not html:
return None

```
medals = []
# Find the medal table - look for wikitable with G S B Total columns
# Wikipedia tables have NOC, Gold, Silver, Bronze, Total
# We'll use regex to extract table rows

# Find the main medal table (first wikitable sortable after "Medal table")
table_match = re.search(
    r'<table[^>]*class="[^"]*wikitable[^"]*sortable[^"]*"[^>]*>(.*?)</table>',
    html, re.DOTALL
)
if not table_match:
    print("  âš ï¸  Could not find medal table on Wikipedia")
    return None

table_html = table_match.group(1)

# Extract rows
rows = re.findall(r'<tr[^>]*>(.*?)</tr>', table_html, re.DOTALL)

for row in rows:
    # Skip header rows and total row
    if '<th' in row and 'Gold' in row:
        continue
    if 'Totals' in row or 'Total' in row:
        continue

    # Extract cells
    cells = re.findall(r'<t[hd][^>]*>(.*?)</t[hd]>', row, re.DOTALL)
    if len(cells) < 5:
        continue

    # Try to find country code/name
    # Wikipedia uses format like: <span ...>Norway</span> (NOR) or similar
    country_cell = cells[0] if cells else ""
    # Try to extract 3-letter code
    code_match = re.search(r'\(([A-Z]{3})\)', country_cell)
    if not code_match:
        # Try href-based detection
        code_match = re.search(r'at_the_2026_Winter_Olympics"[^>]*>([A-Z]{3})', country_cell)
    if not code_match:
        # Try just finding a 3-letter code in a link
        code_match = re.search(r'>([A-Z]{3})<', country_cell)

    if not code_match:
        continue

    code = code_match.group(1)

    # Extract numbers - take last 4 numeric cells
    numbers = []
    for cell in cells:
        clean = re.sub(r'<[^>]+>', '', cell).strip()
        if clean.isdigit():
            numbers.append(int(clean))

    if len(numbers) < 4:
        continue

    # Last 4 numbers should be: rank/gold/silver/bronze/total or gold/silver/bronze/total
    gold, silver, bronze, total = numbers[-4], numbers[-3], numbers[-2], numbers[-1]

    medals.append({
        "country": COUNTRY_NAMES.get(code, code),
        "code": code,
        "flag": FLAG_MAP.get(code, "ğŸ³ï¸"),
        "gold": gold,
        "silver": silver,
        "bronze": bronze,
        "total": total,
    })

if not medals:
    print("  âš ï¸  Parsed 0 medal entries from Wikipedia")
    return None

# Sort by gold, then silver, then bronze
medals.sort(key=lambda x: (-x["gold"], -x["silver"], -x["bronze"]))

# Add ranks
for i, m in enumerate(medals):
    m["rank"] = i + 1

return medals
```

def parse_events_completed(html):
â€œâ€â€œTry to extract number of completed events from Wikipedia.â€â€â€
if not html:
return None
match = re.search(râ€™(\d+)\s*of\s*116\s*events?\s*completedâ€™, html, re.IGNORECASE)
if match:
return int(match.group(1))
# Try alternate pattern
match = re.search(râ€™Completed events\D*(\d+)â€™, html, re.IGNORECASE)
if match:
return int(match.group(1))
return None

def update_via_claude_api(data):
â€œâ€â€
Fallback: Use Claude API with web search to get latest results.
Requires ANTHROPIC_API_KEY environment variable.
â€œâ€â€
api_key = os.environ.get(â€œANTHROPIC_API_KEYâ€)
if not api_key:
print(â€  âš ï¸  No ANTHROPIC_API_KEY set, skipping Claude fallbackâ€)
return None

```
print("  ğŸ¤– Using Claude API fallback...")

import json as json_mod
from urllib.request import urlopen, Request

prompt = """Search for the current 2026 Winter Olympics medal table and any results from today.
```

Return ONLY valid JSON with this exact structure (no markdown, no explanation):
{
â€œevents_completedâ€: <number>,
â€œmedal_tableâ€: [
{â€œcountryâ€: â€œNorwayâ€, â€œcodeâ€: â€œNORâ€, â€œgoldâ€: 0, â€œsilverâ€: 0, â€œbronzeâ€: 0, â€œtotalâ€: 0},
â€¦
],
â€œnew_resultsâ€: [
{â€œevent_id_hintâ€: â€œbrief description like alpine-womens-slalomâ€, â€œresultâ€: â€œshort result like ğŸ¥‡ SHIFFRIN GOLDâ€}
]
}

Include ALL countries that have won at least one medal. Sort by gold medals descending.â€â€â€

```
request_body = json_mod.dumps({
    "model": "claude-haiku-4-5-20251001",
    "max_tokens": 2000,
    "tools": [{"type": "web_search_20250305", "name": "web_search"}],
    "messages": [{"role": "user", "content": prompt}]
}).encode("utf-8")

req = Request("https://api.anthropic.com/v1/messages", data=request_body, headers={
    "Content-Type": "application/json",
    "x-api-key": api_key,
    "anthropic-version": "2023-06-01",
})

try:
    with urlopen(req, timeout=30) as resp:
        response = json_mod.loads(resp.read().decode("utf-8"))
except Exception as e:
    print(f"  âš ï¸  Claude API request failed: {e}")
    return None

# Extract text from response content blocks
text_parts = []
for block in response.get("content", []):
    if block.get("type") == "text":
        text_parts.append(block["text"])

full_text = "\n".join(text_parts)

# Try to extract JSON from the response
# Strip markdown fences if present
clean = re.sub(r'```json\s*', '', full_text)
clean = re.sub(r'```\s*', '', clean)
clean = clean.strip()

try:
    result = json_mod.loads(clean)
except json_mod.JSONDecodeError:
    # Try to find JSON object in the text
    json_match = re.search(r'\{[\s\S]*\}', clean)
    if json_match:
        try:
            result = json_mod.loads(json_match.group())
        except json_mod.JSONDecodeError:
            print("  âš ï¸  Could not parse Claude's response as JSON")
            return None
    else:
        print("  âš ï¸  No JSON found in Claude's response")
        return None

# Validate and add flags/ranks
medal_table = result.get("medal_table", [])
if medal_table:
    for i, entry in enumerate(medal_table):
        code = entry.get("code", "")
        entry["flag"] = FLAG_MAP.get(code, "ğŸ³ï¸")
        entry["rank"] = i + 1
        if "country" not in entry:
            entry["country"] = COUNTRY_NAMES.get(code, code)

return result
```

# Map schedule event IDs to Wikipedia article URL fragments

EVENT_WIKI_MAP = {
â€œalp-m-dhâ€: â€œAlpine_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Men%27s_downhillâ€,
â€œalp-w-dhâ€: â€œAlpine_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_downhillâ€,
â€œalp-w-sgâ€: â€œAlpine_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_super-Gâ€,
â€œalp-w-gsâ€: â€œAlpine_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_giant_slalomâ€,
â€œalp-w-slâ€: â€œAlpine_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_slalomâ€,
â€œfrs-w-slopeâ€: â€œFreestyle_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_slopestyleâ€,
â€œfrs-m-slopeâ€: â€œFreestyle_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Men%27s_slopestyleâ€,
â€œfrs-w-mogulsâ€: â€œFreestyle_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_mogulsâ€,
â€œfrs-m-mogulsâ€: â€œFreestyle_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Men%27s_mogulsâ€,
â€œfrs-w-bigairâ€: â€œFreestyle_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_big_airâ€,
â€œfrs-m-bigairâ€: â€œFreestyle_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Men%27s_big_airâ€,
â€œfrs-w-hpâ€: â€œFreestyle_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_halfpipeâ€,
â€œfrs-w-aerialsâ€: â€œFreestyle_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_aerialsâ€,
â€œfrs-m-aerialsâ€: â€œFreestyle_skiing_at_the_2026_Winter_Olympics_%E2%80%93_Men%27s_aerialsâ€,
â€œsj-m-nhâ€: â€œSki_jumping_at_the_2026_Winter_Olympics_%E2%80%93_Men%27s_normal_hill_individualâ€,
â€œsb-w-bigairâ€: â€œSnowboard_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_big_airâ€,
â€œsb-w-hp-finalâ€: â€œSnowboard_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_halfpipeâ€,
â€œsb-m-hpâ€: â€œSnowboard_at_the_2026_Winter_Olympics_%E2%80%93_Men%27s_halfpipeâ€,
â€œss-m-1000â€: â€œSpeed_skating_at_the_2026_Winter_Olympics_%E2%80%93_Men%27s_1000_metresâ€,
â€œss-m-500â€: â€œSpeed_skating_at_the_2026_Winter_Olympics_%E2%80%93_Men%27s_500_metresâ€,
â€œss-w-500â€: â€œSpeed_skating_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_500_metresâ€,
â€œluge-w-finalâ€: â€œLuge_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_singlesâ€,
â€œluge-relayâ€: â€œLuge_at_the_2026_Winter_Olympics_%E2%80%93_Team_relayâ€,
â€œfs-m-freeâ€: â€œFigure_skating_at_the_2026_Winter_Olympics_%E2%80%93_Men%27s_singlesâ€,
â€œfs-id-freeâ€: â€œFigure_skating_at_the_2026_Winter_Olympics_%E2%80%93_Ice_danceâ€,
â€œfs-w-freeâ€: â€œFigure_skating_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_singlesâ€,
â€œbob-mono-finalâ€: â€œBobsleigh_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_monobobâ€,
â€œhoc-w-goldâ€: â€œIce_hockey_at_the_2026_Winter_Olympics_%E2%80%93_Women%27s_tournamentâ€,
â€œhoc-m-goldâ€: â€œIce_hockey_at_the_2026_Winter_Olympics_%E2%80%93_Men%27s_tournamentâ€,
}

# Reverse lookup: country name fragments to 3-letter codes

NAME_TO_CODE = {}
for code, name in COUNTRY_NAMES.items():
NAME_TO_CODE[name.lower()] = code
# Also add partial names
for part in name.lower().split():
if len(part) > 3:
NAME_TO_CODE[part] = code

# Add common Wikipedia variants

NAME_TO_CODE.update({
â€œswissâ€: â€œSUIâ€, â€œchineseâ€: â€œCHNâ€, â€œamericanâ€: â€œUSAâ€, â€œjapaneseâ€: â€œJPNâ€,
â€œnorwegianâ€: â€œNORâ€, â€œitalianâ€: â€œITAâ€, â€œgermanâ€: â€œGERâ€, â€œfrenchâ€: â€œFRAâ€,
â€œaustrianâ€: â€œAUTâ€, â€œswedishâ€: â€œSWEâ€, â€œcanadianâ€: â€œCANâ€, â€œkoreanâ€: â€œKORâ€,
â€œczechâ€: â€œCZEâ€, â€œslovenianâ€: â€œSLOâ€, â€œdutchâ€: â€œNEDâ€, â€œfinnishâ€: â€œFINâ€,
â€œbritishâ€: â€œGBRâ€, â€œaustralianâ€: â€œAUSâ€,
})

def scrape_event_result(event_id):
â€œâ€â€
Try to scrape the gold medalist from a Wikipedia event page.
Returns a result string like â€˜ğŸ¥‡ GREMAUD (SUI)â€™ or None.

```
Uses multiple strategies with strict validation to avoid garbage results.
"""
wiki_slug = EVENT_WIKI_MAP.get(event_id)
if not wiki_slug:
    return None

url = f"https://en.wikipedia.org/wiki/{wiki_slug}"
html = fetch_url(url)
if not html:
    return None

# First check: does the page indicate the event is COMPLETED?
# If the page says "will be held" but NOT "was held/was won", skip it
text_only = re.sub(r'<[^>]+>', ' ', html)
text_lower = text_only.lower()

# Strong signals the event has NOT happened yet
future_signals = [
    "will be held",
    "will be started",
    "the event will",
    "will take place",
]
past_signals = [
    "was held",
    "was won",
    "won the competition",
    "won the gold",
    "won the event",
    "claimed gold",
    "took gold",
    "finished first",
    "became the champion",
    "became the olympic champion",
    "won the olympic",
]

has_future = any(sig in text_lower for sig in future_signals)
has_past = any(sig in text_lower for sig in past_signals)

# If page only has future tense and no past tense, event hasn't happened
if has_future and not has_past:
    print(f"     â³ Event not completed yet (future tense detected)")
    return None

# Strategy 1: Look for medalist infobox pattern
# Wikipedia uses: {{MedalGold}} or class="gold" or similar
# The most reliable pattern is the medalists section with gold/silver/bronze rows

winner_name = None
country_code = None

# Pattern A: "X won the competition" or "X claimed gold"  
won_patterns = [
    r'([A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+[A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+)+)\s+(?:of\s+)?(\w+)\s+won\s+the\s+competition',
    r'([A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+[A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+)+)\s+(?:of\s+)?(\w+)\s+claimed?\s+(?:the\s+)?(?:olympic\s+)?gold',
    r'([A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+(?:\s+[A-Z][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+)+)\s+(?:of\s+)?(\w+)\s+won\s+(?:the\s+)?(?:olympic\s+)?gold',
]

for pattern in won_patterns:
    m = re.search(pattern, text_only)
    if m:
        winner_name = m.group(1).strip()
        country_word = m.group(2).strip().lower()
        country_code = NAME_TO_CODE.get(country_word)
        if winner_name and country_code:
            break

# Pattern B: Look for medalist template in HTML
# Wikipedia often has: <th>Gold</th>...<td>...<a>Name</a>...<a>Country</a>
if not winner_name:
    # Look for gold medalist in infobox - must have both gold AND silver nearby
    # This prevents matching random "gold" mentions
    gold_section = re.search(
        r'(?:1st\s*place|Gold|gold_medalist|ğŸ¥‡).*?<a[^>]*title="([^"]+)"[^>]*>([^<]+)</a>',
        html, re.DOTALL | re.IGNORECASE
    )
    silver_section = re.search(
        r'(?:2nd\s*place|Silver|silver_medalist|ğŸ¥ˆ)',
        html, re.IGNORECASE
    )
    
    # Only trust gold match if silver is also present (confirms it's a results section)
    if gold_section and silver_section:
        candidate = gold_section.group(2).strip()
        # Validate: name should be 2+ words, not a country/sport name
        words = candidate.split()
        if len(words) >= 2 and len(candidate) > 4:
            # Check it looks like a person's name (capitalized words)
            if all(w[0].isupper() for w in words if w):
                winner_name = candidate
                # Find country code nearby
                context = html[gold_section.start():gold_section.end()+500]
                code_match = re.search(r'\(([A-Z]{3})\)', context)
                if code_match:
                    country_code = code_match.group(1)

# Pattern C: Look for results table with rank column
if not winner_name:
    # Find a table row with rank "1" and extract the athlete name
    rank1_match = re.search(
        r'<t[dh][^>]*>\s*1\s*</t[dh]>.*?<a[^>]*title="([^"]+)"[^>]*>([^<]+)</a>',
        html, re.DOTALL
    )
    if rank1_match:
        candidate = rank1_match.group(2).strip()
        words = candidate.split()
        if len(words) >= 2 and len(candidate) > 4:
            if all(w[0].isupper() for w in words if w):
                winner_name = candidate
                context = html[rank1_match.start():rank1_match.end()+500]
                code_match = re.search(r'\(([A-Z]{3})\)', context)
                if code_match:
                    country_code = code_match.group(1)

if not winner_name:
    return None

# Final validation: result must look like a real name
# Reject single words, numbers, or very short strings
surname = winner_name.split()[-1].upper()
if len(surname) < 2 or surname.isdigit():
    return None

# Reject known garbage patterns
garbage = ['ROUND', 'FINAL', 'QUALIFICATION', 'TRAINING', 'OFFICIAL', 'SESSION', 
           'MEDAL', 'EVENT', 'COMPETITION', 'OLYMPIC', 'WINTER', 'GAMES']
if surname in garbage or winner_name.upper() in garbage:
    return None

if country_code:
    return f"ğŸ¥‡ {surname} ({country_code})"
else:
    return f"ğŸ¥‡ {surname}"
```

def update_event_results(data):
â€œâ€â€
For events marked done but without results, try to scrape Wikipedia.
Only checks medal events (those with ğŸ… in title).
â€œâ€â€
print(â€\nğŸ” Checking for event results on Wikipediaâ€¦â€)
for event in data[â€œscheduleâ€]:
# Only check done medal events without results
if not event[â€œdoneâ€]:
continue
if event.get(â€œresultâ€):
continue
if â€œğŸ…â€ not in event.get(â€œtitleâ€, â€œâ€):
continue

```
    eid = event["id"]
    if eid not in EVENT_WIKI_MAP:
        continue

    print(f"  ğŸ“„ Checking {event['title'][:40]}...")
    result = scrape_event_result(eid)
    if result:
        event["result"] = result
        print(f"     â†’ {result}")
    else:
        print(f"     â†’ No result found yet")
```

def mark_past_events_done(data):
â€œâ€â€
Mark events as done if their date+time is in the past.
Marks done if event started 90+ minutes ago.
â€œâ€â€
et = timezone(timedelta(hours=-5))  # Eastern Time
now = datetime.now(et)

```
for event in data["schedule"]:
    if event["done"]:
        continue

    date_str = event["date"]
    time_str = event["time"]

    if time_str == "TBD":
        continue

    try:
        # Parse "2026-02-12" and "5:30 AM"
        dt = datetime.strptime(f"{date_str} {time_str}", "%Y-%m-%d %I:%M %p")
        dt = dt.replace(tzinfo=et)

        # Mark as done if event started 90+ minutes ago
        if now - dt > timedelta(minutes=90):
            event["done"] = True
            print(f"  âœ… Auto-marked done: {event['title']}")
    except ValueError:
        continue
```

def main():
print(â€œğŸ… Olympics Tracker Updateâ€)
print(fâ€   Time: {datetime.now().strftime(â€™%Y-%m-%d %H:%M:%S UTCâ€™)}â€)
print()

```
# Load current data
with open(DATA_FILE, "r") as f:
    data = json.load(f)

updated = False

# --- Step 1: Try Wikipedia scrape ---
print("ğŸ“¡ Fetching Wikipedia medal table...")
html = fetch_url(WIKI_MEDAL_URL)
medals = parse_wiki_medal_table(html)
events_done = parse_events_completed(html)

if medals:
    print(f"  âœ… Got {len(medals)} countries from Wikipedia")
    data["medal_table"] = medals
    updated = True

    # Log USA status
    usa = next((m for m in medals if m["code"] == "USA"), None)
    if usa:
        print(f"  ğŸ‡ºğŸ‡¸ USA: {usa['gold']}G {usa['silver']}S {usa['bronze']}B = {usa['total']} total")
else:
    print("  âŒ Wikipedia scrape failed. No fallback configured.")
    print("  ğŸ’¡ To add Claude API fallback, set ANTHROPIC_API_KEY env var.")

if events_done and events_done != data.get("events_completed"):
    data["events_completed"] = events_done
    print(f"  ğŸ“Š Events completed: {events_done}/116")
    updated = True

# --- Step 2: Auto-mark past events as done ---
print("\nâ° Checking event times...")
mark_past_events_done(data)

# --- Step 2b: Try to fill in results for done medal events ---
update_event_results(data)

# --- Step 3: Always update timestamp and save ---
data["last_updated"] = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%S+00:00")
with open(DATA_FILE, "w") as f:
    json.dump(data, f, indent=2, ensure_ascii=False)
print(f"\nğŸ’¾ Data saved to {DATA_FILE}")

print("âœ… Done!")
return 0
```

if **name** == â€œ**main**â€:
sys.exit(main())